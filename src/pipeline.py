# pipeline.py
import logging
import shutil
import json
import torch
import time
from pathlib import Path
from typing import List, Dict

# Import your existing modules
from config import segmentation_config, cell_config, report_config, SlideReport
from segment import SegmentationEngine
from cell_infer import CellInferenceEngine
from aggregate_adaptive import ClinicalAggregator
from report_gen import ClinicalReportGenerator

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("PipelineOrchestrator")

class InferencePipeline:
    def __init__(self):
        """
        Initializes all heavy models ONCE at startup.
        This prevents reloading weights for every request.
        """
        logger.info("[OK] System Startup: Initializing AI Models...")
        
        # 1. Load Segmentation Model (Cellpose)
        logger.info("   - Loading Segmentation Engine...")
        self.seg_engine = SegmentationEngine(segmentation_config)
        
        # 2. Load Classification Model (MobileViT)
        logger.info("   - Loading Inference Engine...")
        self.inf_engine = CellInferenceEngine(cell_config)
        
        # 3. Load Logic & Reporting
        self.aggregator = ClinicalAggregator(report_config)
        
        self.is_ready = True
        logger.info("[OK] Pipeline Ready for Inference.")

    def run_slide_analysis(self, slide_id: str, image_paths: List[Path]) -> Dict:
        """
        Main Execution Flow: 
        Input Images -> Segment -> Classify -> Aggregate -> PDF
        """
        start_time = time.time()
        logger.info(f"[{slide_id}] Processing {len(image_paths)} frames...")

        # --- STEP 1: SEGMENTATION (Batch Loop) ---
        all_cells_metadata = []
        
        for img_path in image_paths:
            try:
                self.seg_engine._process_single_image(img_path)
                
                # Read the metadata file generated by segmentation
                json_name = img_path.stem + ".json"
                meta_path = segmentation_config.OUTPUT_DIR / "metadata" / json_name
                
                if meta_path.exists():
                    with open(meta_path, 'r') as f:
                        data = json.load(f)
                        all_cells_metadata.extend(data['cells'])
            except Exception as e:
                logger.error(f"[{slide_id}] Segmentation error on {img_path.name}: {e}")

        logger.info(f"[{slide_id}] Segmentation Complete. Found {len(all_cells_metadata)} cells total.")

        # --- STEP 2: CLASSIFICATION (Inference) ---
        processed_cells = []
        
        for cell_meta in all_cells_metadata:
            try:
                # Construct path to the crop
                crop_filename = cell_meta['crop_path']
                crop_path = segmentation_config.OUTPUT_DIR / "crops" / crop_filename
                
                if crop_path.exists():
                    # Run MobileViT Inference
                    prediction = self.inf_engine._infer_single_cell(crop_path)
                    
                    # Merge Spatial Info (BBox) with Biological Info (Class)
                    merged_record = {**cell_meta, **prediction}
                    processed_cells.append(merged_record)
            except Exception as e:
                pass # Skip bad cells

        # --- STEP 3: AGGREGATION ---
        logger.info(f"[{slide_id}] Aggregating Clinical Report...")
        report_obj: SlideReport = self.aggregator.analyze_slide(slide_id, processed_cells)

        # --- STEP 4: REPORTING (PDF & JSON) ---
        # Define Paths
        json_out_path = report_config.OUTPUT_JSON_DIR / f"{slide_id}_report.json"
        pdf_out_path = report_config.OUTPUT_PDF_DIR / f"{slide_id}_report.pdf"
        
        # Save Intermediate JSON
        self.aggregator.save_for_pdf(report_obj, str(json_out_path))
        
        # PDF path 
        pdf_out_path = report_config.OUTPUT_PDF_DIR / f"{slide_id}_report.pdf"
        # Generate PDF
        try:
            pdf_gen = ClinicalReportGenerator(str(json_out_path))
            pdf_gen.generate_pdf(str(pdf_out_path))
        except Exception as e:
            logger.error(f"[{slide_id}] PDF Generation failed: {e}")

        processing_time = round(time.time() - start_time, 2)
        
        # Return pure data for API response
        return {
            "slide_id": slide_id,
            "status": "completed",
            "risk_flag": report_obj.summary.risk_flag,
            "total_cells": len(processed_cells),
            "processing_time": processing_time,
            "pdf_local_path": str(pdf_out_path),
            "pdf_url": f"/download/reports/{slide_id}_report.pdf",
            "details": report_obj.summary
        }


if __name__ == "__main__":
    # Example usage when running as valid script
    # Setup Input
    input_dir = segmentation_config.INPUT_DIR
    if not input_dir.exists():
        logger.warning(f"Input directory {input_dir} does not exist. Creating it...")
        input_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"Please place frame images in {input_dir} and run again.")
    else:
        # data/Test_APC/*
        valid_extensions = {".jpg", ".jpeg", ".png", ".bmp", ".tiff"}
        image_paths = [
            p for p in input_dir.iterdir() 
            if p.suffix.lower() in valid_extensions and p.is_file()
        ]
        
        if not image_paths:
            logger.warning(f"No images found in {input_dir}. Please add images.")
        else:
            # Initialize
            pipeline = InferencePipeline()
            
            # Run
            # Treat the folder as one "Slide" for this demo
            slide_id = input_dir.name 
            
            logger.info(f"Starting pipeline for Slide ID: {slide_id}")
            result = pipeline.run_slide_analysis(slide_id, image_paths)
            
            # Output
            print("\n" + "="*40)
            print(f"PIPELINE COMPLETE: {slide_id}")
            print(f"Risk Flag: {result['risk_flag']}")
            print(f"Report PDF: {result['pdf_local_path']}")
            print("="*40 + "\n")