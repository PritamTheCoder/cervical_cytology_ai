# pipeline.py
import logging
import shutil
import json
import torch
import time
from pathlib import Path
from typing import List, Dict

# Import your existing modules
from config import segmentation_config, cell_config, report_config, SlideReport
from segment import SegmentationEngine
from cell_infer import CellInferenceEngine
from aggregate_adaptive import ClinicalAggregator
from report_gen import ClinicalReportGenerator

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("PipelineOrchestrator")

class InferencePipeline:
    def __init__(self):
        """
        Initializes all heavy models ONCE at startup.
        This prevents reloading weights for every request.
        """
        logger.info("[OK] System Startup: Initializing AI Models...")
        
        # 1. Load Segmentation Model (Cellpose)
        logger.info("   - Loading Segmentation Engine...")
        self.seg_engine = SegmentationEngine(segmentation_config)
        
        # 2. Load Classification Model (MobileViT)
        logger.info("   - Loading Inference Engine...")
        self.inf_engine = CellInferenceEngine(cell_config)
        
        # 3. Load Logic & Reporting
        self.aggregator = ClinicalAggregator(report_config)
        
        self.is_ready = True
        logger.info("[OK] Pipeline Ready for Inference.")

    def run_slide_analysis(self, slide_id: str, image_paths: List[Path]) -> Dict:
        """
        Main Execution Flow: 
        Input Images -> Segment -> Classify -> Aggregate -> PDF
        """
        start_time = time.time()
        logger.info(f"[{slide_id}] Processing {len(image_paths)} frames...")

        # --- STEP 1: SEGMENTATION (Batch Loop) ---
        all_cells_metadata = []
        
        for img_path in image_paths:
            # We call the internal process method. 
            # Note: Ensure segment.py's _process_single_image returns the list of cell dicts
            try:
                # Assuming _process_single_image saves crops and returns metadata
                # You might need to slightly tweak segment.py to return the 'cells' list directly
                # If segment.py saves a JSON, we read it back:
                self.seg_engine._process_single_image(img_path)
                
                # Read the metadata file generated by segmentation
                json_name = img_path.stem + ".json"
                meta_path = segmentation_config.OUTPUT_DIR / "metadata" / json_name
                
                if meta_path.exists():
                    with open(meta_path, 'r') as f:
                        data = json.load(f)
                        all_cells_metadata.extend(data['cells'])
            except Exception as e:
                logger.error(f"[{slide_id}] Segmentation error on {img_path.name}: {e}")

        logger.info(f"[{slide_id}] Segmentation Complete. Found {len(all_cells_metadata)} cells total.")

        # --- STEP 2: CLASSIFICATION (Inference) ---
        processed_cells = []
        
        for cell_meta in all_cells_metadata:
            try:
                # Construct path to the crop
                crop_filename = cell_meta['crop_path']
                crop_path = segmentation_config.OUTPUT_DIR / "crops" / crop_filename
                
                if crop_path.exists():
                    # Run MobileViT Inference
                    prediction = self.inf_engine._infer_single_cell(crop_path)
                    
                    # Merge Spatial Info (BBox) with Biological Info (Class)
                    merged_record = {**cell_meta, **prediction}
                    processed_cells.append(merged_record)
            except Exception as e:
                pass # Skip bad cells

        # --- STEP 3: AGGREGATION ---
        # This uses your logic to calculate Risk, Ratios, and High/Low Confidence
        logger.info(f"[{slide_id}] Aggregating Clinical Report...")
        report_obj: SlideReport = self.aggregator.analyze_slide(slide_id, processed_cells)

        # --- STEP 4: REPORTING (PDF & JSON) ---
        # Define Paths
        json_out_path = report_config.OUTPUT_JSON_DIR / f"{slide_id}_report.json"
        pdf_out_path = report_config.OUTPUT_PDF_DIR / f"{slide_id}_report.pdf"
        
        # Save Intermediate JSON
        self.aggregator.save_for_pdf(report_obj, str(json_out_path))
        
        # PDF path 
        pdf_out_path = report_config.OUTPUT_PDF_DIR / f"{slide_id}_report.pdf"
        # Generate PDF
        try:
            pdf_gen = ClinicalReportGenerator(str(json_out_path))
            pdf_gen.generate_pdf(str(pdf_out_path))
        except Exception as e:
            logger.error(f"[{slide_id}] PDF Generation failed: {e}")

        processing_time = round(time.time() - start_time, 2)
        
        # Return pure data for API response
        return {
            "slide_id": slide_id,
            "status": "completed",
            "risk_flag": report_obj.summary.risk_flag,
            "total_cells": len(processed_cells),
            "processing_time": processing_time,
            "pdf_local_path": str(pdf_out_path),
            "pdf_url": f"/download/reports/{slide_id}_report.pdf",
            "details": report_obj.summary
        }